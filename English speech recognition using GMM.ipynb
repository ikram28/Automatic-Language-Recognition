{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b441db",
   "metadata": {},
   "source": [
    "# Importing necassary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0967e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from python_speech_features import mfcc\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import soundfile as sf\n",
    "import random\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f70050f",
   "metadata": {},
   "source": [
    "# Defining the function that reads the audios from a given path using scipy and returns 3 lists : audios, freqs, filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b439b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audios(path):\n",
    "    audios = []\n",
    "    freqs = []\n",
    "    filepaths = []\n",
    "    #walking through the directory that contains the dataset and reading each file that has the .wav extension\n",
    "    for dp, dn, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.wav'):\n",
    "                filepath = os.path.join(dp, filename)\n",
    "                filepaths.append(filepath)\n",
    "                with open(filepath, \"rb\") as f:\n",
    "                    # load the audio using scipy\n",
    "                    freq, data = scipy.io.wavfile.read(f, mmap=False)\n",
    "                    # append the data and frequency to the respective lists\n",
    "                    audios.append(data)\n",
    "                    freqs.append(freq)\n",
    "    return audios, freqs, filepaths\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac9df8",
   "metadata": {},
   "source": [
    "# Defining the funcyion that extracts the mfcc features then removes the frames of silence finally it saves the mffc features into a .txt file according to gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb308ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMfccs_RemoveSilence_saveMfccs(audios,freqs,filepaths, directory):\n",
    "    mfccs = []\n",
    " \n",
    "    for audio, freq, filepath in zip(audios, freqs,filepaths):\n",
    "        # extract the MFCC features\n",
    "        mfcc_features = mfcc(audio, freq, winlen=0.025, winstep=0.01, numcep=13, nfilt=26, nfft= 2048, lowfreq=0,\n",
    "                         highfreq=None, preemph=0.97, ceplifter=22, appendEnergy=False)\n",
    "        \n",
    "        # calculate the energy\n",
    "        energy = np.sum(mfcc_features**2, axis=1)\n",
    "        # calculate the threshold for silence\n",
    "        threshold = np.mean(energy) * 0.4\n",
    "        #removing silence frames from mfccs\n",
    "        voiced_indices = np.where(energy > threshold)[0]\n",
    "        mfccs_voiced = mfcc_features[voiced_indices,:]\n",
    "        mfccs.append(mfccs_voiced)\n",
    "        \n",
    "        # print the shape of the MFCCs before and after removing silence\n",
    "        print(f\"MFCCs before removing silence: {mfcc_features.shape}\")\n",
    "        print(f\"MFCCs after removing silence: {mfccs_voiced.shape}\")\n",
    "        \n",
    "       #saving mffcs \n",
    "       # extract the gender information from the file name\n",
    "        gender = None\n",
    "        if 'hommes' in filepath:\n",
    "            gender = 'Hommes'\n",
    "        elif 'femmes' in filepath:\n",
    "            gender = 'Femmes'\n",
    "\n",
    "        # save the MFCCs to the appropriate directory based on gender\n",
    "        if gender is not None:\n",
    "            gender_dir = os.path.join(directory, gender)\n",
    "            if not os.path.exists(gender_dir):\n",
    "                os.makedirs(gender_dir)\n",
    "            mfcc_file = os.path.join(gender_dir,  os.path.splitext(os.path.basename(filepath))[0] + \".mfcc\")\n",
    "            np.savetxt(mfcc_file, mfccs_voiced, delimiter=',')\n",
    "            \n",
    "      \n",
    "    \n",
    "    return  mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a1b86",
   "metadata": {},
   "source": [
    "# Defining the function that splits the extraced mfccs into training and testing sets : 2/3 from male directory for training and 2/3 from female "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8259ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(mfcc_dir):\n",
    "    # create separate lists for male and female file paths\n",
    "    male_files = []\n",
    "    female_files = []\n",
    "    for root, dirs, files in os.walk(mfcc_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.mfcc'):\n",
    "                if 'Hommes' in root:\n",
    "                    male_files.append(os.path.join(root, file))\n",
    "                elif 'Femmes' in root:\n",
    "                    female_files.append(os.path.join(root, file))\n",
    "\n",
    "    # shuffle the male and female lists independently\n",
    "    random.shuffle(male_files)\n",
    "    random.shuffle(female_files)\n",
    "\n",
    "    # split the male and female lists into train and test based on the desired ratio\n",
    "    male_train = male_files[:int(2/3*len(male_files))]\n",
    "    male_test = male_files[int(2/3*len(male_files)):]\n",
    "\n",
    "    female_train = female_files[:int(2/3*len(female_files))]\n",
    "    female_test = female_files[int(2/3*len(female_files)):]\n",
    "\n",
    "    \n",
    "    \n",
    "    # merge the train and test lists for both male and female\n",
    "    train_files = male_train + female_train\n",
    "    test_files = male_test + female_test\n",
    "\n",
    "    # load the MFCC features from the saved files for the train and test sets\n",
    "    train_mfccs = []\n",
    "    test_mfccs = []\n",
    "\n",
    "    for file in train_files:\n",
    "        train_mfccs.append(np.loadtxt(file, delimiter=','))\n",
    "\n",
    "    for file in test_files:\n",
    "        test_mfccs.append(np.loadtxt(file, delimiter=','))\n",
    "\n",
    "    # print the shapes of the train and test MFCC feature arrays\n",
    "    print(f\"Train male MFCCs shape: {np.array(male_train).shape}\")\n",
    "    print(f\"Test male MFCCs shape: {np.array( male_test).shape}\")\n",
    "    print(f\"Train female MFCCs shape: {np.array(female_train).shape}\")\n",
    "    print(f\"Test female MFCCs shape: {np.array( female_test).shape}\")\n",
    "    print(f\"Train MFCCs shape: {np.array(train_mfccs).shape}\")\n",
    "    print(f\"Test MFCCs shape: {np.array(test_mfccs).shape}\")\n",
    "    \n",
    "    return train_mfccs, test_mfccs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad0d967",
   "metadata": {},
   "source": [
    "# Defining the functions that train the different GMM models and than save them as a pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8bd0e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm16(train_mfccs):\n",
    "    # Initialize the GMM model with 16 classes\n",
    "    gmm = GaussianMixture(n_components=16, covariance_type='diag', random_state=0)\n",
    "\n",
    "    # Fit the GMM model to the training data\n",
    "    gmm.fit(train_mfccs)\n",
    "    \n",
    "    # Save the trained GMM model to a file\n",
    "    joblib.dump(gmm, r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\gmm\\english\\gmm_model16_english.pkl')\n",
    "\n",
    "    return gmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dacbf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm32(train_mfccs):\n",
    "    # Initialize the GMM model with 32 classes\n",
    "    gmm = GaussianMixture(n_components=32, covariance_type='diag', random_state=0)\n",
    "\n",
    "    # Fit the GMM model to the training data\n",
    "    gmm.fit(train_mfccs)\n",
    "    \n",
    "    # Save the trained GMM model to a file\n",
    "    joblib.dump(gmm, r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\gmm\\english\\gmm_model32_english.pkl')\n",
    "\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b6eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm64(train_mfccs):\n",
    "    # Initialize the GMM model with 64 classes\n",
    "    gmm = GaussianMixture(n_components=64, covariance_type='diag', random_state=0)\n",
    "\n",
    "    # Fit the GMM model to the training data\n",
    "    gmm.fit(train_mfccs)\n",
    "    \n",
    "    # Save the trained GMM model to a file\n",
    "    joblib.dump(gmm, r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\gmm\\english\\gmm_model64_english.pkl')\n",
    "\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0bc521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm128(train_mfccs):\n",
    "    # Initialize the GMM model with 128 classes\n",
    "    gmm = GaussianMixture(n_components=128, covariance_type='diag', random_state=0)\n",
    "\n",
    "    # Fit the GMM model to the training data\n",
    "    gmm.fit(train_mfccs)\n",
    "    \n",
    "    # Save the trained GMM model to a file\n",
    "    joblib.dump(gmm, r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\gmm\\english\\gmm_model128_english.pkl')\n",
    "\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "612098fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm256(train_mfccs):\n",
    "    # Initialize the GMM model with 254 classes\n",
    "    gmm = GaussianMixture(n_components=256, covariance_type='diag', random_state=0)\n",
    "\n",
    "    # Fit the GMM model to the training data\n",
    "    gmm.fit(train_mfccs)\n",
    "    \n",
    "    # Save the trained GMM model to a file\n",
    "    joblib.dump(gmm, r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\gmm\\english\\gmm_model256_english.pkl')\n",
    "\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb45460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm512(train_mfccs):\n",
    "    # Initialize the GMM model with 254 classes\n",
    "    gmm = GaussianMixture(n_components=512, covariance_type='diag', random_state=0)\n",
    "\n",
    "    # Fit the GMM model to the training data\n",
    "    gmm.fit(train_mfccs)\n",
    "    \n",
    "    # Save the trained GMM model to a file\n",
    "    joblib.dump(gmm, r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\gmm\\english\\gmm_model512_english.pkl')\n",
    "\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0434482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm1024(train_mfccs):\n",
    "    # Initialize the GMM model with 254 classes\n",
    "    gmm = GaussianMixture(n_components=1024, covariance_type='diag', random_state=0)\n",
    "\n",
    "    # Fit the GMM model to the training data\n",
    "    gmm.fit(train_mfccs)\n",
    "    \n",
    "    # Save the trained GMM model to a file\n",
    "    joblib.dump(gmm, r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\gmm\\english\\gmm_model1024_english.pkl')\n",
    "\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df1901",
   "metadata": {},
   "source": [
    "# Getting the audios frequencies and filepaths from the russe directory using the function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "691321ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_7292\\2069710646.py:13: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  freq, data = scipy.io.wavfile.read(f, mmap=False)\n"
     ]
    }
   ],
   "source": [
    "audios, freqs, filepaths= read_audios(r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\dataset\\english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a44575",
   "metadata": {},
   "source": [
    "# Extracting the mfcc features - Removing silence and saving the mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cb16fef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCs before removing silence: (11994, 13)\n",
      "MFCCs after removing silence: (11984, 13)\n",
      "MFCCs before removing silence: (3230, 13)\n",
      "MFCCs after removing silence: (3051, 13)\n",
      "MFCCs before removing silence: (12120, 13)\n",
      "MFCCs after removing silence: (11679, 13)\n",
      "MFCCs before removing silence: (11997, 13)\n",
      "MFCCs after removing silence: (11988, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (11511, 13)\n",
      "MFCCs before removing silence: (11974, 13)\n",
      "MFCCs after removing silence: (11958, 13)\n",
      "MFCCs before removing silence: (11994, 13)\n",
      "MFCCs after removing silence: (11977, 13)\n",
      "MFCCs before removing silence: (13136, 13)\n",
      "MFCCs after removing silence: (12160, 13)\n",
      "MFCCs before removing silence: (9143, 13)\n",
      "MFCCs after removing silence: (9028, 13)\n",
      "MFCCs before removing silence: (12120, 13)\n",
      "MFCCs after removing silence: (11918, 13)\n",
      "MFCCs before removing silence: (5247, 13)\n",
      "MFCCs after removing silence: (4407, 13)\n",
      "MFCCs before removing silence: (6296, 13)\n",
      "MFCCs after removing silence: (5102, 13)\n",
      "MFCCs before removing silence: (12120, 13)\n",
      "MFCCs after removing silence: (11861, 13)\n",
      "MFCCs before removing silence: (12120, 13)\n",
      "MFCCs after removing silence: (11650, 13)\n",
      "MFCCs before removing silence: (11992, 13)\n",
      "MFCCs after removing silence: (11946, 13)\n",
      "MFCCs before removing silence: (12192, 13)\n",
      "MFCCs after removing silence: (11980, 13)\n",
      "MFCCs before removing silence: (7636, 13)\n",
      "MFCCs after removing silence: (5971, 13)\n",
      "MFCCs before removing silence: (10801, 13)\n",
      "MFCCs after removing silence: (10791, 13)\n",
      "MFCCs before removing silence: (1835, 13)\n",
      "MFCCs after removing silence: (1514, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (11693, 13)\n",
      "MFCCs before removing silence: (12120, 13)\n",
      "MFCCs after removing silence: (11940, 13)\n",
      "MFCCs before removing silence: (12131, 13)\n",
      "MFCCs after removing silence: (12009, 13)\n",
      "MFCCs before removing silence: (12120, 13)\n",
      "MFCCs after removing silence: (11829, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (11517, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (10284, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (10982, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (11475, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (11181, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (9884, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (10369, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (10557, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (10245, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (11017, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (9809, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (10403, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (10373, 13)\n",
      "MFCCs before removing silence: (11999, 13)\n",
      "MFCCs after removing silence: (10464, 13)\n"
     ]
    }
   ],
   "source": [
    "mfccs = extractMfccs_RemoveSilence_saveMfccs(audios, freqs, filepaths,r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\mfcc\\english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c215355",
   "metadata": {},
   "source": [
    "## -----> We can see here that the size of the mfcc features has decreased after removing the frames ot silence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433fa3a",
   "metadata": {},
   "source": [
    "# Splitting into teest and train sets according to gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88efb508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train male MFCCs shape: (18,)\n",
      "Test male MFCCs shape: (10,)\n",
      "Train female MFCCs shape: (6,)\n",
      "Test female MFCCs shape: (3,)\n",
      "Train MFCCs shape: (24,)\n",
      "Test MFCCs shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_7292\\3397580047.py:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(f\"Train MFCCs shape: {np.array(train_mfccs).shape}\")\n",
      "C:\\Temp\\ipykernel_7292\\3397580047.py:46: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(f\"Test MFCCs shape: {np.array(test_mfccs).shape}\")\n"
     ]
    }
   ],
   "source": [
    "train_mfccs, test_mfccs = train_test_split(r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\mfcc\\english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc25031",
   "metadata": {},
   "source": [
    "# Stacking vertically the train and test MFCC features so that we can fit the gmm models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1453682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack vertically the train MFCC features \n",
    "mfcc_train = []\n",
    "for train_mfcc in train_mfccs:\n",
    "    mfcc_train.append(train_mfcc)\n",
    "mfcc_train = np.concatenate(mfcc_train, axis=0)\n",
    "\n",
    "#stack vertically the test MFCC features \n",
    "mfcc_test = []\n",
    "for test_mfcc in test_mfccs:\n",
    "    mfcc_test.append(test_mfcc)\n",
    "mfcc_test = np.concatenate(mfcc_test, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb378a1",
   "metadata": {},
   "source": [
    "# Saving the test set into a txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8254a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the test mfccs in a file\n",
    "test_mfccs = np.vstack(test_mfccs)\n",
    "test_mfccs = np.array(test_mfccs, dtype=float)\n",
    "np.savetxt(r'C:\\Users\\ASUS ROG STRIX\\Desktop\\Projet\\Langues\\gmm\\Test\\englishTest', test_mfccs, delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c7eab2",
   "metadata": {},
   "source": [
    "# Training the different Gmm Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7f1788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm16 = gmm16(mfcc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caf46091",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm32 = gmm32(mfcc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f95e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm64 = gmm64(mfcc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60fcf0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm128= gmm128(mfcc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70009491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gmm256= gmm256(mfcc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c775f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm512= gmm512(mfcc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a230d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm1024= gmm1024(mfcc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57307236",
   "metadata": {},
   "source": [
    "# Evaluate the performance of each GMM model on the test set using the score_samples() function that returns an array containing the log-likelihood of each frame of the mfcc features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "864627f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM16 score: [-55.95076016 -51.53906862 -52.30335213 ... -53.38977504 -53.73184251\n",
      " -52.78500515]\n",
      "GMM32 score: [-52.22076254 -50.39426146 -50.25463041 ... -54.15932864 -54.00620841\n",
      " -53.10609041]\n",
      "GMM64 score: [-53.34392749 -50.50381756 -50.44347015 ... -54.0731192  -54.37504843\n",
      " -52.98074161]\n",
      "GMM128 score: [-52.36388278 -51.29821973 -50.27367576 ... -53.70667849 -53.47532677\n",
      " -52.69576983]\n",
      "GMM256 score: [-54.70755715 -51.53593765 -48.56805656 ... -52.64522452 -52.46768875\n",
      " -52.38062009]\n",
      "GMM512 score: [-54.2624491  -51.76055412 -48.29771514 ... -50.47587363 -50.17484681\n",
      " -52.93099567]\n",
      "GMM1024 score: [-53.62434973 -50.951523   -49.18429121 ... -48.61093581 -48.89695807\n",
      " -53.04050903]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for model in [gmm16, gmm32, gmm64, gmm128, gmm256, gmm512, gmm1024]:\n",
    "    score = model.score_samples(mfcc_test)\n",
    "    scores.append(score)\n",
    "\n",
    "# Print the scores\n",
    "print('GMM16 score:', scores[0])\n",
    "print('GMM32 score:', scores[1])\n",
    "print('GMM64 score:', scores[2])\n",
    "print('GMM128 score:', scores[3])\n",
    "print('GMM256 score:', scores[4])\n",
    "print('GMM512 score:', scores[5])\n",
    "print('GMM1024 score:', scores[6])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5b35d",
   "metadata": {},
   "source": [
    "# As we can see in the following lines our mfcc_test set contains 138959 frames so we expect the same size of the scores array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a160dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138959, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64110e6",
   "metadata": {},
   "source": [
    "# Indeed the size of the scores array is the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e793c874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138959,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " scores[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199e421",
   "metadata": {},
   "source": [
    "# In order to compare between the different GMM Models we need to calculate the score for the hole test set and we can do that by calculating the mean of the individual scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bddb6015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM16 score: -52.34479365423865\n",
      "GMM32 score: -51.9048062447987\n",
      "GMM64 score: -51.406454637529656\n",
      "GMM128 score: -51.08107606459406\n",
      "GMM256 score: -50.91016505216264\n",
      "GMM512 score: -50.88396417598292\n",
      "GMM1024 score: -50.72819687682046\n"
     ]
    }
   ],
   "source": [
    "#calculationg the score of the hole test set\n",
    "print('GMM16 score:', scores[0].mean())\n",
    "print('GMM32 score:', scores[1].mean())\n",
    "print('GMM64 score:', scores[2].mean())\n",
    "print('GMM128 score:', scores[3].mean())\n",
    "print('GMM256 score:', scores[4].mean())\n",
    "print('GMM512 score:', scores[5].mean())\n",
    "print('GMM1024 score:', scores[6].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3e080",
   "metadata": {},
   "source": [
    "### From the results above we can see that the best score (the closest one to 0) is given by the model using 512 gaussians "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
